{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Random Forest\n",
    "\n",
    "In this Lab, you will implement a very simplified version of the Random Forest classifier. Make sure that you check the videos of lecture 4 before starting this Lab:\n",
    "- Decision Tree and Random Forest: https://youtu.be/YSy9S2OsXNo\n",
    "\n",
    "Random Forst (RF) works as follows:\n",
    "\n",
    "- Given a dataset $X \\in \\mathbb{R}^{n \\times d}$, RF selects randomly some features (i.e. `n_features`) from the dataset (where `n_features << d`). It also selects a random subset of the data (with `n_samples` data-points). Then, it builds a Decision Tree from those selected features and samples.\n",
    "\n",
    "- Repeats this process `n_trees` times so that you have a number of `n_trees` Decision Trees built from different random combinations of features and different random subsets of data.\n",
    "\n",
    "- To predict, RF takes each of the `n_trees` built Decision Trees and predict the outputs (classes); then it calculates the votes for each predicted class-label and takes the mode (most frequent label). In other words, considers the high voted predicted label as the final prediction from the random forest algorithm.\n",
    "\n",
    "## Loading the dataset:\n",
    "The code below will load a training dataset into variables `X` and `y` as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.62365962 78.02469282]\n",
      " [30.28671077 43.89499752]\n",
      " [35.84740877 72.90219803]\n",
      " [60.18259939 86.3085521 ]\n",
      " [79.03273605 75.34437644]]\n",
      "[0. 0. 0. 1. 1.]\n",
      "(100, 2) (100,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "\n",
    "filename = \"datasets/university-admission-dataset.csv\"\n",
    "mydata = np.genfromtxt(filename, delimiter=\",\")\n",
    "X = mydata[:, :2]\n",
    "y = mydata[:, -1]\n",
    "\n",
    "\"\"\" TODO:\n",
    "Print a small subset of X and y to see how the data looks like.\n",
    "\"\"\"\n",
    "print(X[:5])\n",
    "print(y[:5])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn.tree.DecisionTreeClassifier\n",
    "To simplify the implementation of our Random Forest classifier, we will use an existing implementation of the `DecisionTreeClassifier` available in the sklearn library. Read the following code to see an example of how to use the `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "Training Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TODO:\n",
    "Read and run the following example code to see how to use a \n",
    "simple DecisionTreeClassifier to make predictions.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(X, y) # Training\n",
    "preds = clf.predict(X) # Predicting\n",
    "\n",
    "print(\"Predictions:\", preds)\n",
    "\n",
    "acc = np.mean(preds == y) * 100\n",
    "print(\"Training Accuracy: {}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a simplified random forest classifier\n",
    "Complete the code below to implement a random forest classifier.\n",
    "\n",
    "In Python, to select a list of `k` random integers between `0` and `nbr` (excluded), you can use `ids = np.random.choice(nbr, k, replace=False)`. The keyword `replace=False` means that we don't want to select the same number more than once (so, ids with contain `k` unique integers).\n",
    "\n",
    "Also, to compute the mode (most common or frequent label), you can make use of the function `scipy.stats.mode` if you want. Read its documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 85.0%\n",
      "Training Accuracy: 87.0%\n",
      "Training Accuracy: 88.0%\n",
      "Training Accuracy: 87.0%\n",
      "Training Accuracy: 85.0%\n",
      "Training Accuracy: 83.0%\n",
      "Training Accuracy: 84.0%\n",
      "Training Accuracy: 83.0%\n",
      "Training Accuracy: 85.0%\n",
      "Training Accuracy: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# clf = clfs[0][0]\n",
    "for clfa in clfs:\n",
    "    clf = clfa[0]\n",
    "    preds = clf.predict(X[:,clfa[1]])\n",
    "    acc = np.mean(preds == y) * 100\n",
    "    print(\"Training Accuracy: {}%\".format(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Testing your implementation a dataset with multiple features\n",
    "This part is optional.\n",
    "\n",
    "Test you random forest implementation on a dataset with more features (e.g. you can add more polynomial features to the previous dataset or use any other dataset with a high number of features).\n",
    "\n",
    "Compute the generalization accuracy of your random forest on that dataset using a 10-fold-cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (optional) ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}