{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7 : Neural Networks\n",
    "\n",
    "Please check the videos of lecture 7 (neural networks - part 1 and 2) before doing this Lab.\n",
    "\n",
    "Classifiers such as logistic regression cannot directly form more complex hypotheses as it is only a linear classifier. In this Lab, you will implement a neural network from scrach to recognize handwritten digits. The neural network will be able to result in a complex model that forms a non-linear hypotheses.\n",
    "\n",
    "To start, you will be using parameters from a neural network that we have already trained. Your goal is to implement the feedforward propagation algorithm to use our provided weights for prediction. Then, you will implement the backpropagation algorithm for learning the neural network parameters (i.e. weights) and apply it to the task of hand-written digit recognition.\n",
    "\n",
    "Before starting this Lab, we strongly recommend reading the slides of lecture 6.\n",
    "\n",
    "# 1. Dataset and Visualization\n",
    "For this Lab, you will use a dataset to recognize handwritten digits (from 0 to 9). Automated handwritten digit recognition is widely used today - from recognizing zip codes (postal codes) on mail envelopes to recognizing amounts written on bank checks automatically. This Lab will show you how the methods you've learned can be used for this classification task.\n",
    "\n",
    "You are given a data set in `digits-dataset.mat` that contains $n = 5000$ training examples of handwritten digits. Each training example is a vector in $\\mathbb{R}^d$ where $d=400$, resulting from a 20 pixel by 20 pixel grayscale image of the digit. In order words, each pixel is represented by a floating point number indicating the grayscale intensity at that location; the 20 by 20 grid of pixels was \"*unrolled*\" (i.e. flattened) into a 400-dimensional vector. So, each of these training examples becomes a single row in our data matrix $X$. This gives us a $5000 \\times 400$ matrix $X \\in \\mathbb{R}^{5000 \\times 400}$ where every row is a training example for a handwritten digit image.\n",
    "\n",
    "The second part of the training set is a vector $y$ of dimension 5000, that contains labels for the training set.\n",
    "\n",
    "Complete the following Python code to:\n",
    "- Load the dataset\n",
    "- Visualize it using PCA (you can use `sklearn.decomposition.PCA` for this) as shown on the following figure.\n",
    "- Visualize some data-points as images of digits.\n",
    "\n",
    "<img src=\"imgs/plotDigitsDataset.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (5000, 400), y.shape: (5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div id='d5c6c427-88fc-431b-8366-06755d6adec1'></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import loadmat\n",
    "\n",
    "filename = \"datasets/digits-dataset.mat\"\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Complete the following code to load the dataset from \n",
    "`filename` into variables X (inputs) and y (outputs).\n",
    "\"\"\"\n",
    "mat = loadmat(filename)\n",
    "X = mat[\"X\"]\n",
    "y = mat[\"y\"].reshape(len(X))\n",
    "print(\"X.shape: {}, y.shape: {}\".format(X.shape, y.shape))\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Visualization: produce a 2d scatter plot of the data after applying PCA.\n",
    "\"\"\"\n",
    "def visualize_pca(X):\n",
    "    X_pca = PCA(n_components = 2).fit_transform(X)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    X10_pca, X1_pca, X2_pca, X3_pca, X4_pca, X5_pca, X6_pca, X7_pca, X8_pca, X9_pca  = \\\n",
    "        X_pca[y==0], X_pca[y==1], X_pca[y==2], X_pca[y==3], X_pca[y==4], X_pca[y==5], X_pca[y==6], X_pca[y==7], X_pca[y==8], X_pca[y==9]\n",
    "    ax.scatter(X1_pca[:, 0], X1_pca[:, 1], marker=\"o\", color=\"blue\", label=\"Class 1\")\n",
    "    ax.scatter(X2_pca[:, 0], X2_pca[:, 1], marker=\".\", color=\"orange\", label=\"Class 2\")\n",
    "    ax.scatter(X3_pca[:, 0], X3_pca[:, 1], marker=\"+\", color=\"green\", label=\"Class 3\")\n",
    "    ax.scatter(X4_pca[:, 0], X4_pca[:, 1], marker=\"*\", color=\"red\", label=\"Class 4\")\n",
    "    ax.scatter(X5_pca[:, 0], X5_pca[:, 1], marker=\"D\", color=\"purple\", label=\"Class 5\")\n",
    "    ax.scatter(X6_pca[:, 0], X6_pca[:, 1], marker=\"s\", color=\"brown\", label=\"Class 6\")\n",
    "    ax.scatter(X7_pca[:, 0], X7_pca[:, 1], marker=\"x\", color=\"pink\", label=\"Class 7\")\n",
    "    ax.scatter(X8_pca[:, 0], X8_pca[:, 1], marker=\"3\", color=\"grey\", label=\"Class 8\")\n",
    "    ax.scatter(X9_pca[:, 0], X9_pca[:, 1], marker=\"<\", color=\"yellow\", label=\"Class 9\")\n",
    "    ax.scatter(X10_pca[:, 0], X10_pca[:, 1], marker=\"^\", color=\"cyan\", label=\"Class 10\")\n",
    "    ax.set_xlabel(\"Principal Componant 1\")\n",
    "    ax.set_ylabel(\"Principal componant 2\")\n",
    "    ax.set_title(\"Training dataset visualization using PCA\")\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "\n",
    "\"\"\" TODO:\n",
    "Read the following function then call it on the loaded input data X \n",
    "to visualize the original digits (each digit is a 20*20 image).\n",
    "\"\"\"\n",
    "def visualize_100_digits(X):\n",
    "    # Pick 100 randomly chosen data-points and reshape them to 20*20 images.\n",
    "    ids = np.random.choice(len(X), 100, replace=False)\n",
    "    images = X[ids].reshape(100, 20, 20) # 100 images shaped as 20*20\n",
    "\n",
    "    print(\"Plotting digits ... This may take few seconds ...\")\n",
    "    fig, axes = plt.subplots(10, 10)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            img = images[i*10+j].T\n",
    "            axes[i][j].imshow( img, cmap='gray' )\n",
    "            axes[i][j].axis(\"off\")\n",
    "    fig.show()\n",
    "\n",
    "# TODO: call the function visualize_100_digits(X) here.\n",
    "visualize_pca(X)\n",
    "# visualize_100_digits(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural Network\n",
    "Our neural network is shown in the following figure:\n",
    "<img src=\"imgs/NeuralNetwork.png\" width=\"400px\" />\n",
    "\n",
    "This neural network has 3 layers: an input layer $a^{(1)}$, a hidden layer $a^{(2)}$ and an output layer $a^{(3)}$. It also has two matrices of parameters: $\\Theta^{(1)}$ (connecting the two first layers), and $\\Theta^{(2)}$ (connecting the two second layers).\n",
    "\n",
    "Recall that our inputs are pixel values of digit images. Since the images are of size $20 \\times 20$, this gives us $400$ input layer units (not counting the extra bias unit which is always $+1$). So, if we feed just **one data-point** $x \\in \\mathbb{R}^{400}$ to our input layer, then we should have $a^{(1)} \\in \\mathbb{R}^{401}$. However, if we stack **all our $n$ data-points** as columns into a matrix $X^T \\in \\mathbb{R}^{400 \\times n}$ (i.e. transpose of the original $X$ matrix) and add the extra feature $x_0 = 1$ to each data-point (i.e. add a row of ones to $X^T$), then our input layer would be $a^{(1)} \\in \\mathbb{R}^{401 \\times n}$.\n",
    "\n",
    "Recall also that the number of classes we have is $K = 10$ classes and each of our class-labels $y^{(i)} \\in \\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\}$. In this multi-class classification problem, for each input vector $x$, the output layer $a^{(3)}$ should output a $K$ dimensional vector. Therefore, we should encode each of our class-labels $y^{(i)}$ (from $y$) as a **one-hot-vector** of dimension $K$. In other words, the labels vector $y$ of dimension $n$ should be encoded as a matrix $Y$ of dimension $K \\times n$.\n",
    "\n",
    "Also, remember that in this case, if the number of units in the hidden layer is $\\text{hunits}$, then the first parameters matrix will be $\\Theta^{(1)} \\in \\mathbb{R}^{\\text{hunits} ~ \\times ~ (400+1)}$, and the second parameters matrix will be $\\Theta^{(2)} \\in \\mathbb{R}^{K ~ \\times ~ (\\text{hunits}+1)}$.\n",
    "\n",
    "The general algorithm for training a neural network with 3 layers (i.e. with one hidden layer) can be summarized as follows. The most important parts of the algorithm are the **feedforward** and **backpropagation** that you will implement in the next sections. Please read and understand the following general code:\n",
    "\n",
    "```python\n",
    "def neural_network_training(X, y, max_iterations=1000, alpha=1e-3, hunits=25):\n",
    "    a1 = add_row_ones(X.T)    # create an input layer of dimension (401 * n)\n",
    "    Y = vectorize_outputs(y) # encode the labels vector y as a matrix Y of dimension (K * n)\n",
    "    \n",
    "    # Generating randomly the initial weights (parameters values)\n",
    "    Theta1 = np.random.randn(hunits, a1.shape[0])   # Parameters matrix of dimension (hunits * 401)\n",
    "    Theta2 = np.random.randn(Y.shape[0], hunits+1)  # Parameters matrix of dimension K * (hunits+1)\n",
    "    \n",
    "    # Iterative optimization of the parameters\n",
    "    for itr in range(max_iterations):\n",
    "        z2, a2, z3, a3 = feedforward(a1, Theta1, Theta2) # Feedforward propagation\n",
    "        DELTA1, DELTA2 = backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2) # Backpropagation\n",
    "        \n",
    "        # Update the parameters using gradient descent\n",
    "        Theta1 = Theta1 - alpha * DELTA1\n",
    "        Theta2 = Theta2 - alpha * DELTA2\n",
    "        \n",
    "    return Theta1, Theta2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Some Useful Functions\n",
    "Before proceeding, we first provide in this section some useful functions.\n",
    "\n",
    "The first function is `add_row_ones(A)`. It takes a given matrix `A` (two dimensional numpy array) and returns a new matrix based on `A` with an additional first row of ones. This will be helpful later, for example, when you want to feed the data to the input layer. Remember that $X \\in \\mathbb{R}^{d \\times n}$ (in our digits dataset $d=400, n=5000$) and $a^{(1)} \\in \\mathbb{R}^{(d+1) \\times n}$. So, to feed the dataset to the input layer, we can transpose $X$ and add a row of ones to it: `add_row_ones(X.T)` (which would be in $\\mathbb{R}^{(d+1) \\times n}$).\n",
    "\n",
    "The second function is `vectorize_outputs(y)`. It takes an array of class-labels $y$ and returns a matrix $Y$ where the $i^{th}$ column in $Y$ corresponds to the one-hot-vector of the $i^{th}$ class-label $y^{(i)}$ in $y$. This will be helpful later when we want to compare the output of the last layer $a^{(3)} \\in \\mathbb{R}^{K \\times n}$ to the true output $Y  \\in \\mathbb{R}^{K \\times n}$.\n",
    "\n",
    "The third function is `sigmoid(z)`. It computes the sigmoid defined as: $\\text{sigmoid}(z) = g(z) = \\frac{1}{1 + e^{-z}}$. This function works when the argument $z$ is a scalar value, a vector, or a matrix. For a vector or a matrix, the function will perform the sigmoid function on every element. This function will be useful later on when you implement feedforward and backpropagation.\n",
    "\n",
    "The forth function is `sigmoid_deriv(z)` which is the derivative of the sigmoid function defined as: $\\frac{\\partial}{\\partial z} g(z) = g(z) (1 - g(z))$. This function works when the argument $z$ is a scalar value, a vector, or a matrix. For a vector or a matrix, the function will apply the derivative on every element. This function will be useful later on when you implement backpropagation.\n",
    "\n",
    "You don't have to implement anything in this section. Just read the code before running it to understand what each function does.\n",
    "\n",
    "**Important Note:** In this lab we are using the sigmoid function as an activation function for our hidden layer just for an educational purpose. However, you should be aware that it is usually **not** a good idea to use the sigmoid activation function for the hidden layers (especially if you have several hidden layers), as it may suffer from the **vanishing gradient problem**. In reality, it is usually better to use a simpler activation function such as ReLU (Rectified Linear Unit) and have more hidden layers. For more information about this topic, please read: https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neural_network_training(X, y, max_iterations=1000, alpha=1e-3, hunits=25):\n",
    "    a1 = add_row_ones(X.T)    # create an input layer of dimension (401 * n)\n",
    "    Y = vectorize_outputs(y) # encode the labels vector y as a matrix Y of dimension (K * n)\n",
    "\n",
    "    # Generating randomly the initial weights (parameters values)\n",
    "    Theta1 = np.random.randn(hunits, a1.shape[0])   # Parameters matrix of dimension (hunits * 401)\n",
    "    Theta2 = np.random.randn(Y.shape[0], hunits+1)  # Parameters matrix of dimension K * (hunits+1)\n",
    "\n",
    "    # Iterative optimization of the parameters\n",
    "    for itr in range(max_iterations):\n",
    "        z2, a2, z3, a3 = feedforward(a1, Theta1, Theta2) # Feedforward propagation\n",
    "        DELTA1, DELTA2 = backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2) # Backpropagation\n",
    "\n",
    "        # Update the parameters using gradient descent\n",
    "        Theta1 = Theta1 - alpha * DELTA1\n",
    "        Theta2 = Theta2 - alpha * DELTA2\n",
    "\n",
    "    return Theta1, Theta2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " add_row_ones(...) \n",
      " [[ 1.  1.  1.  1.]\n",
      " [ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]]\n",
      "\n",
      " vectorize_outputs(...) corresponding to [2 0 2 3 1 1] is:\n",
      " [[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      " sigmoid(...) \n",
      " [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
      "\n",
      " sigmoid_deriv(...) \n",
      " [0.00664806 0.10499359 0.19661193 0.25       0.19661193 0.10499359\n",
      " 0.00664806]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function returns a new matrix based on A with an \n",
    "additional first row of ones. \"\"\"\n",
    "def add_row_ones(A):\n",
    "    row_ones = np.ones((1, A.shape[1]))\n",
    "    return np.append(row_ones, A, axis=0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function returns a (K * n) matrix where the i'th column is the \n",
    "one-hot-vector corresponding to the i'th class-label in y. \"\"\"\n",
    "def vectorize_outputs(y):\n",
    "    K = len(set(y)) # number of unique classes\n",
    "    return np.eye(K)[y].T\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function computes the sigmoid. The argument z can be a \n",
    "scalar value, a vector, or a matrix.\n",
    "\"\"\"\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function computes the gradient of the sigmoid function. \n",
    "The argument z can be a scalar value, a vector, or a matrix.\n",
    "\"\"\"\n",
    "def sigmoid_deriv(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "The following code test the functions defined above on some simple\n",
    "examples. Run it to test it and understand what these functions do.\n",
    "\"\"\"\n",
    "result = add_row_ones(\n",
    "    np.array([\n",
    "        [1, 2,  3,  4], \n",
    "        [5, 6,  7,  8], \n",
    "        [9, 10, 11, 12]])\n",
    ")\n",
    "print(\"\\n add_row_ones(...) \\n\", result)\n",
    "\n",
    "arr = np.array([2, 0, 2, 3, 1, 1])\n",
    "result = vectorize_outputs(arr)\n",
    "print(\"\\n vectorize_outputs(...) corresponding to {} is:\\n {}\".format(arr, result))\n",
    "\n",
    "result = sigmoid( np.array([-2, -1, 0, 1, 2]) )\n",
    "print(\"\\n sigmoid(...) \\n\", result)\n",
    "\n",
    "result = sigmoid_deriv( np.array([-5, -2, -1, 0, 1, 2, 5]) )\n",
    "print(\"\\n sigmoid_deriv(...) \\n\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feedforward Propagation, Prediction and Cost Function\n",
    "In this section, you have been provided with a set of network parameters $(\\Theta^{(1)}, \\Theta^{(2)})$ already trained by us. These are stored in `ANNweights.mat` and are loaded in the following Python code into matrices `Theta1` and `Theta2`. The parameters have dimensions that are sized for a neural network with $\\text{hunits}=25$ hidden units in the second layer and $K=10$ output units (corresponding to the 10 digit classes).\n",
    "\n",
    "<img src=\"imgs/neuralNetWorkArch.png\" width=\"400px\" />\n",
    "\n",
    "Run the following Python code to load the provided parameters $\\Theta^{(1)}$ and $\\Theta^{(2)}$. The rows in the matrices `Theta1` and `Theta2` correspond to the parameters of each unit. For example, the first row of `Theta1` corresponds to the first hidden unit in the second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta1.shape: (25, 401), Theta2.shape: (10, 26)\n"
     ]
    }
   ],
   "source": [
    "mat = loadmat(\"datasets/ANNweights.mat\")\n",
    "\n",
    "Theta1 = mat[\"Theta1\"]\n",
    "Theta2 = mat[\"Theta2\"]\n",
    "\n",
    "print(\"Theta1.shape: {}, Theta2.shape: {}\".format(Theta1.shape, Theta2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Feedforward Propagation\n",
    "Now you will implement feedforward propagation for the neural network. You should implement the feedforward computation that computes the output $a^{(3)} \\in \\mathbb{R}^{K, n}$ for all examples in our training set $X$ at once. To do so, the input `a1` (first argument of the function `feedforward(a1, Theta1, Theta2)`) is expected to be an array of shape `(d+1, n))`, i.e. `(401, 5000)` for our digits dataset.\n",
    "\n",
    "Your code should also work for a dataset of any size, with any number of labels (you can assume that there are always at least $K \\geq 3$ labels).\n",
    "\n",
    "Before starting to implement the function `feedforward(..)`, read the full Python code below. Particularly, notice at the end of the code that the input is prepared for you as `a1 = add_row_ones(X.T)` before calling the function `feedforward(..)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: X: (5000, 400), a1: (401, 5000), y: (5000,), Theta1: (25, 401), Theta2: (10, 26)\n",
      "a3.shape: (10, 5000)\n",
      "\n",
      "*** Output corresponding to the first data-point:\n",
      " [9.99634467e-01 1.24468845e-06 3.88789472e-04 3.20959468e-04\n",
      " 7.96742710e-07 5.32264192e-04 1.97184774e-04 4.41761567e-04\n",
      " 2.24608757e-05 5.60473860e-05]\n",
      "*** The corresponding predicted class-label (for the first data-point) is: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TODO:\n",
    "First, read the full Python code of this cell. Then, write \n",
    "the definition of the function feedforward(...) below.\n",
    "\"\"\"\n",
    "def feedforward(a1, Theta1, Theta2):\n",
    "    pass\n",
    "    # TODO: compute z2 as explained in the figure above.\n",
    "    z2 = Theta1 @ a1\n",
    "    # TODO: compute a2 as explained in the figure above.\n",
    "    a2 = sigmoid(z2)\n",
    "    # TODO: add a row of ones to a2 as explained in the figure above.\n",
    "    a2 = add_row_ones(a2)\n",
    "    \n",
    "    # TODO: compute z3 as explained in the figure above.\n",
    "    z3 = Theta2 @ a2\n",
    "    # TODO: compute a3 as explained in the figure above.\n",
    "    a3 = sigmoid(z3)\n",
    "    # TODO: uncomment the next line to return the results (z2, a2, z3, a3)\n",
    "    return z2, a2, z3, a3\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Uncomment the following code and read it. It calls your function feedforward(...) \n",
    "and check the output corresponding to the first data-point in the training set. \n",
    "The predicted class-label for this first data-point should be 0.\n",
    "\"\"\"\n",
    "\n",
    "##### Uncomment the following code:\n",
    "\n",
    "a1 = add_row_ones(X.T)   # We create the input a1 of dimension ((d+1) * n)\n",
    "print(\"Shapes: X: {}, a1: {}, y: {}, Theta1: {}, Theta2: {}\"\n",
    "      .format(X.shape, a1.shape, y.shape, Theta1.shape, Theta2.shape))\n",
    "\n",
    "ffresults = feedforward(a1, Theta1, Theta2)\n",
    "\n",
    "# The last element returned from feedforward(..) is a3\n",
    "a3 = ffresults[-1]\n",
    "print(\"a3.shape: {}\\n\".format(a3.shape))\n",
    "\n",
    "# The first column in a3 is the predicted output (as a vector of dim K=10) corresponding of the first data-point\n",
    "arr = a3[:, 0]\n",
    "print(\"*** Output corresponding to the first data-point:\\n\", arr)\n",
    "print(\"*** The corresponding predicted class-label (for the first data-point) is:\", np.argmax(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 5000)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999858850959062\n",
      "6.5567172084137925e-06\n",
      "0.00017165139977693957\n",
      "7.511269294478828e-05\n",
      "5.712879477863555e-07\n",
      "0.008579028187641814\n",
      "0.00016008480799401876\n",
      "0.0004994336574074482\n",
      "1.0846506462687551e-05\n",
      "0.0004209243758727879\n"
     ]
    }
   ],
   "source": [
    "for i in a3[:,1]:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "(10,)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3[:,1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predicting class-labels\n",
    "Once you have implemented and tested the `feedforward(a1, Theta1, Theta2)` function, you will complete the Python code below to implement the function `predict(X, Theta1, Theta2)`.\n",
    "\n",
    "This function should take a dataset $X \\in \\mathbb{R}^{n \\times d}$, create an input $a^{(1)} \\in \\mathbb{R}^{(d+1) ~ \\times ~ n}$ based on $X$, perform a feedforward propagation to get the outputs $a^{(3)} \\in \\mathbb{R}^{K \\times n}$ from the neural network, and finally return the corresponding predicted class-labels. Note that the column $i$ from $a^{(3)}$ corresponds to the output $h_\\Theta(x^{(i)})$ of data-point $x^{(i)}$. The predicted class-label for this data-point is the label that has the largest output $(h_\\Theta(x^{(i)}))_k$\n",
    "\n",
    "Once you are done, the code will call your `predict(..)` function using the loaded set of parameters for `Theta1` and `Theta2`. You should see that the accuracy on the training set is about $98.6\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.61999999999999\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TODO:\n",
    "Write the definition of the predict(..) function which takes a new dataset X, the \n",
    "parameters Theta1 and Theta2, and returns the predicted classes for the data-points in X. \n",
    "In other words, the function should return an array of n predicted class-labels.\n",
    "\"\"\"\n",
    "def predict(X, Theta1, Theta2):\n",
    "    a1 = add_row_ones(X.T)\n",
    "    ffresults = feedforward(a1, Theta1, Theta2)\n",
    "    a3 = ffresults[-1]\n",
    "\n",
    "    a4 = []\n",
    "    for i in range(a3.shape[1]):\n",
    "        a4.append(np.argmax(a3[:,i]))\n",
    "\n",
    "    a4 = np.array(a4)\n",
    "    return a4\n",
    "\n",
    "\"\"\" TODO:\n",
    "Uncomment the lines below to test your function predict(..) on the training \n",
    "data X. If you implemented the functions predict(..) and feedforward(..) \n",
    "correctly, then you should see a training accuracy of about 98.6%.\n",
    "\"\"\"\n",
    "y_pred = predict(X, Theta1, Theta2)\n",
    "print(\"Accuracy: \", (y == y_pred).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cost Function\n",
    "Now you need to complete the following Python code to implement the cost function `E_unregularized(...)`. Recall that the cost function for the neural network (without regularization) is\n",
    "$$\n",
    "E(\\Theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{k=1}^{K} \\left [ -y_k^{(i)} \\log{( (h_\\Theta(x^{(i)}))_k )} - (1 - y_k^{(i)}) \\log{( 1 - (h_\\Theta(x^{(i)}))_k )} \\right ], \n",
    "$$\n",
    "where $h_\\Theta(x^{(i)})$ is computed as shown in the previous figure (of the ANN architecture) and $K = 10$ is the total number of possible labels. Note that $h_\\Theta(x^{(i)})_k$ is the output value (in the last layer) of the $k^{th}$ output unit for data-point $x^{(i)}$. Also, recall that whereas the original labels (in the variable $y$) were $1, 2, \\dots, 10$, for the purpose of training a neural network we need to recode the labels as vectors containing only values $0$ or\n",
    "$1$ (i.e. one-hot-vectors), so that\n",
    "$$\n",
    "y^{(i)} = \n",
    "\\begin{bmatrix}\n",
    "1\\\\ \n",
    "0\\\\ \n",
    "0\\\\ \n",
    "\\vdots \\\\\n",
    "0 \n",
    "\\end{bmatrix}, \\quad\n",
    "\\begin{bmatrix}\n",
    "0\\\\ \n",
    "1\\\\ \n",
    "0\\\\ \n",
    "\\vdots \\\\\n",
    "0 \n",
    "\\end{bmatrix}, \\quad\n",
    "\\dots, \\text{ or } \\quad\n",
    "\\begin{bmatrix}\n",
    "0\\\\ \n",
    "0\\\\ \n",
    "0\\\\ \n",
    "\\vdots \\\\\n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "For example, if $x^{(i)}$ is an image of the digit 5, then the corresponding $y^{(i)}$ (that you should use with the cost function) should be a 10-dimensional vector with $y^{(i)}_5 = 1$, and the other elements equal to $0$. This kind of encoding is called \"*one hot vector*\" encoding. The following Python code calls the function `vectorize_outputs(y)` which encodes for you the original vector of labels $y$ (of dimension $n$) into a matrix $Y$ (of dimension $K \\times n$).\n",
    "\n",
    "Once you are done, call your `E_unregularized(..)` using the loaded set of parameters for `Theta1` and `Theta2`. You should see that the cost is about $0.15835$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "5000"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y = vectorize_outputs(y)\n",
    "Yt = Y.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drawme = []\n",
    "for i in Yt:\n",
    "    drawme.append(np.where(i == 1)[0][0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()     # create a figure with one subplot\n",
    "ax.scatter(range(len(drawme)), drawme) # scatter plot of all the data\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 5000)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unregularized cost: 0.15835957478763854\n"
     ]
    }
   ],
   "source": [
    "# Encoding the class-labels as one hot vectors\n",
    "Y = vectorize_outputs(y)\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Write the definition of the cost function E(..) for the specified neural network.\n",
    "\"\"\"\n",
    "def E_unregularized(X, Y, Theta1, Theta2):\n",
    "    # TODO: Prepare the neural network input a1 based on X\n",
    "    a1 = add_row_ones(X.T)\n",
    "    # TODO: Perform a feedforward propagation to get the outputs\n",
    "    z2, a2, z3, a3 = feedforward(a1, Theta1, Theta2)\n",
    "    # TODO: Compute the (unregularized) cost indicated in the previous formula.\n",
    "    cost = 0\n",
    "    for i in range(a3.shape[1]):\n",
    "        for k in range(a3.shape[0]):\n",
    "            cost += (-Y[:,i][k] * np.log(a3[:, i][k])) - ((1 - Y[:,i][k]) * np.log(1 - a3[:, i][k]))\n",
    "    cost /= a3.shape[1]\n",
    "    return cost\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Call your cost function E_unregularized using the training set X, Y and the loaded parameters \n",
    "Theta1 and Theta2. If your implementation is correct, you should see a cost of about 0.15835\n",
    "\"\"\"\n",
    "cost = E_unregularized(X, Y, Theta1, Theta2)\n",
    "print(\"Unregularized cost:\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now implement the cost function for neural networks with regularization. This regularized cost is given by\n",
    "$$\n",
    "E(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{k=1}^{K} \\left [ -y_k^{(i)} \\log{( (h_\\theta(x^{(i)}))_k )} - (1 - y_k^{(i)}) \\log{( 1 - (h_\\theta(x^{(i)}))_k )} \\right ] + \\frac{\\lambda}{2n} \\left [ \\sum_{j=1}^{25} \\sum_{k=1}^{400} (\\Theta_{j,k}^{(1)})^2 + \\sum_{j=1}^{10} \\sum_{k=1}^{25} (\\Theta_{j,k}^{(2)})^2 \\right ]. \n",
    "$$\n",
    "\n",
    "You can assume that the neural network will only have 3 layers: an input layer, a hidden layer and an output layer. However, your code should work for any number of input units, hidden units and outputs units. While we have explicitly listed the indices above for $\\Theta^{(1)}$ and $\\Theta^{(2)}$ for clarity, do note that **your code should in general work with $\\Theta^{(1)}$ and $\\Theta^{(2)}$ of any size**.\n",
    "\n",
    "Note that you should not be regularizing the terms that correspond to the bias. For the matrices `Theta1` and `Theta2`, this corresponds to the first column of each matrix. You should now add regularization to your cost function. Notice that you can first compute the unregularized cost function $E$ using your existing `E_unregularized(..)` and then later add the cost for the regularization terms.\n",
    "\n",
    "Once you are done, call your function `E_regularized(..)` using the loaded set of parameters for `Theta1` and `Theta2`, and $\\lambda = 1$. You should see that the cost is about $1.37917$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized cost 1.389396703136274\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TODO:\n",
    "Write the definition of the regularized cost function for the specified neural network.\n",
    "\"\"\"\n",
    "def E_regularized(X, Y, Theta1, Theta2, lmd):\n",
    "\n",
    "    cost = E_unregularized(X, Y, Theta1, Theta2)\n",
    "    regularization1 = 0\n",
    "    regularization2 = 0\n",
    "    for j in range(Theta1.shape[0]):\n",
    "        for k in range(Theta1.shape[1]):\n",
    "            regularization1 += Theta1[j][k]**2\n",
    "    for j in range(Theta2.shape[0]):\n",
    "        for k in range(Theta2.shape[1]):\n",
    "            regularization2 += Theta2[j][k]**2\n",
    "    r_cost = (lmd / (2 * a3.shape[1])) * (regularization1 + regularization2)\n",
    "    r_cost += cost\n",
    "    return r_cost\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Call your cost function E_regularized using the training set X, Y and the loaded parameters \n",
    "Theta1 and Theta2. If your implementation is correct, you should see a cost of about 1.37917\n",
    "\"\"\"\n",
    "cost = E_regularized(X, Y, Theta1, Theta2, lmd = 1)\n",
    "print(\"Regularized cost\", cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Backpropagation\n",
    "In the previous sections, you implemented feedforward propagation for neural networks and used it to predict handwritten digits with the parameters (weights) we provided. In this section, you will implement the backpropagation algorithm to learn the parameters for the neural network. The backpropagation algorithm allows to compute the gradient for the neural network cost function. You will first implement the backpropagation algorithm to compute the gradients for the parameters for the (unregularized) neural network. After you have verified that your gradient computation for the unregularized case is correct, you will implement the gradient for the regularized neural network. Once you have computed the gradient, you will be able to train the neural network by minimizing the cost function $E(\\theta)$ using a simple optimization procedure such as gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Backpropagation without Regularization\n",
    "<img src=\"imgs/BackpropagationNNArchitecture.png\" width=\"400px\" />\n",
    "\n",
    "Recall that the intuition behind the backpropagation algorithm is as follows. Given a training example $(x^{(t)}, y^{(t)})$, we will first run a \"*forward pass*\" to compute all the activations throughout the network, including the output value of the hypothesis $h_\\Theta(x)$. Then, for each node $j$ in layer $l$, we would like to compute an \"*error term*\" $\\delta_j^{(l)}$ that measures how much that node was \"responsible\" for any errors in our output.\n",
    "\n",
    "For an output node, we can directly measure the difference between the network's activation and the true target value, and use that to define $\\delta_j^{(3)}$ (since layer 3 is the output layer). For the hidden units, you will compute $\\delta_j^{(l)}$ based on a weighted average of the error terms of the nodes in layer $(l + 1)$, as depicted in the above figure.\n",
    "\n",
    "In more details, here is how the neural network training works:\n",
    "\n",
    "1. In the function `neural_network_training(..)` given below, we encode $y$ (the true class-labels) as a matrix $Y$ (as explained previously); we use the input data $X \\in \\mathbb{R}^{n ~ \\times ~ d}$) to set our input layer `a1` $\\in \\mathbb{R}^{(d+1) ~ \\times ~ n}$; then, we initialize the parameters matrices `Theta1` and `Theta2` randomly.\n",
    "\n",
    "2. We iterate several times with a loop `for itr in range(max_iterations): ...` until convergence or until we reach `max_iterations`. At each iteration we do the following:\n",
    "  1. We perform a feedforward propagation pass in order to compute the activations $(z^{(2)}, a^{(2)}, z^{(3)}; a^{(3)})$ for layers 2 and 3 using our previously defined function: `z2, a2, z3, a3 = feedforward(a1, Theta1, Theta2)`.\n",
    "  2. We perform a backpropagation pass in order to compute the gradients `D1` and `D2`, using the backpropagation function defined below: `D1, D2 = backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2)`.\n",
    "  3. We perform a gradient descent step to update the matrices parameters `Theta1` and `Theta2`.\n",
    "  \n",
    "\n",
    "The backpropagation function `backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2)` is given to you in the following code. You are asked to read it and understand how it works. Here is some explanation to help you better understand it:\n",
    "1. First, we compute the erros (`delta3`) at the output layer as follows: $\\delta^{(3)} = (a^{(3)} - Y)$. This is possible since $a^{(3)} \\in \\mathbb{R}^{K ~ \\times ~ n}$ and $Y \\in \\mathbb{R}^{K ~ \\times ~ n}$ are of the same dimensions.\n",
    "\n",
    "2. For layer 2 (our hidden layer), we first need to compute $(\\Theta^{(2)})^T \\delta^{(3)}$. Notice that $\\Theta_2 \\in \\mathbb{R}^{K ~ \\times ~ (\\text{hunits+1})}$ and $\\delta^{(3)} \\in \\mathbb{R}^{K ~ \\times ~ n}$, so the product $(\\Theta^{(2)})^T \\delta^{(3)}$ is possible and the result `result_temp = (Theta2.T @ delta3)` will be in $\\mathbb{R}^{(\\text{hunits+1}) ~ \\times ~ n}$. Next, we ignore the first row from this result as it is associated with the additional bias unit: `result_temp = result_temp[1:]`. Then, we need to elementwise-multiply this result with $g'(z^{(2)})$, where $g'(.)$ is the derivative of the activation function (i.e. `sigmoid_deriv(z2)`). This is done with `delta2 =  result_temp * sigmoid_deriv(z2)`. Note that this elementwise multiplication is possible as $g'(z^{(2)}) \\in \\mathbb{R}^{\\text{hunits} ~ \\times ~ n}$. Also, note that there is no $\\delta^{(1)}$ to compute, as layer 1 corresponds to our input data (which does not change).\n",
    "\n",
    "3. Finally, the (unregularized) gradients $\\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} E(\\Theta)$ with respect to the parameters of $\\Theta^{(l)}$ are obtained in $\\Delta^{(l)}$ (which is of the same dimensions as $\\Theta^{(l)}$) using the formula: $$\\Delta^{(l)} = \\frac{1}{n} \\big [ \\delta^{(l+1)} (a^{(l)})^T \\big ].$$ In the code below, `DELTA1` corresponds to $\\Delta^{(1)}$, and `DELTA2` corresponds to $\\Delta^{(2)}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO:\n",
    "Read the definition of the backpropagation function and run this cell.\n",
    "\"\"\"\n",
    "def backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2):\n",
    "    delta3 = 2 * (a3 - Y)\n",
    "    \n",
    "    result_temp = (Theta2.T @ delta3)\n",
    "    result_temp = result_temp[1:] # we ignore the first row\n",
    "    delta2 =  result_temp * sigmoid_deriv(z2)\n",
    "    \n",
    "    n = a1.shape[1]\n",
    "    \n",
    "    DELTA2 = (1/n) * (delta3 @ a2.T)\n",
    "    DELTA1 = (1/n) * (delta2 @ a1.T)\n",
    "    \n",
    "    return DELTA1, DELTA2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we defined the backpropagation algorithm (to compute the gradients), we will use it below to train the neural network and compute its training accuracy. This will allow you to increase your confidence that your code is computing the gradients correctly. The function `neural_network_training(..)` in the following Python code, uses your functions `feedforward(..)` and `backpropagation(..)` to train the neural network (i.e. learn its parameters). Read the code and then run it to test your backpropagation implementation. If your implementation was correct, then you should expect a training accuracy of more than $95\\%$ when `neural_network_training(..)` is called with `max_iterations = 2000` (iterations of gradient descent), `alpha = 0.5` (learning rate of gradient descent), and `hunits = 25` (units in the hidden layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "(401, 5000)"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "(25, 401)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr = 1950, cost = 0.33228012580034216 \r\n",
      "Accuracy:  95.89999999999999\n",
      "[[ 4.48284072e-05  0.00000000e+00  0.00000000e+00 ...  3.12933757e-07\n",
      "  -3.61468190e-08  0.00000000e+00]\n",
      " [ 7.12118566e-04  0.00000000e+00  0.00000000e+00 ...  6.47806524e-08\n",
      "   1.10156727e-09  0.00000000e+00]\n",
      " [ 3.28475566e-05  0.00000000e+00  0.00000000e+00 ... -3.93410591e-13\n",
      "  -3.60038770e-14  0.00000000e+00]\n",
      " ...\n",
      " [-5.45188958e-04  0.00000000e+00  0.00000000e+00 ... -1.33640264e-08\n",
      "   6.42430973e-11  0.00000000e+00]\n",
      " [-2.89641956e-04  0.00000000e+00  0.00000000e+00 ...  5.48465450e-08\n",
      "   1.54517188e-09  0.00000000e+00]\n",
      " [-1.42355239e-04  0.00000000e+00  0.00000000e+00 ... -3.88011023e-07\n",
      "   4.02860270e-08  0.00000000e+00]] [[ 5.08628844e-04  1.55861112e-04 -1.12820572e-03 -2.88851822e-04\n",
      "   3.87348456e-04  6.13705927e-04 -4.11949268e-04  4.90044909e-04\n",
      "  -7.84581078e-05  7.68648717e-04 -3.83675318e-04  2.00240667e-04\n",
      "   1.87518017e-04 -7.69144398e-04  3.68947793e-04 -3.92657636e-04\n",
      "   1.67998661e-04  1.39974004e-05  1.34365685e-03  5.10243173e-04\n",
      "  -2.26901996e-04  9.90743979e-05 -7.45902830e-04  6.61376559e-04\n",
      "   2.93508223e-04  8.89028405e-04]\n",
      " [ 1.73761212e-04 -2.50212936e-04  1.14773879e-03  2.06947415e-05\n",
      "  -1.84762360e-04 -5.65226394e-04  1.76821935e-04 -6.75386873e-05\n",
      "   2.32346855e-04  7.21980159e-04 -2.79811153e-04 -1.44082571e-04\n",
      "  -7.94796174e-04  2.25375806e-05 -3.32617356e-06 -5.07576018e-04\n",
      "   7.02724717e-04 -1.02635921e-05  4.34792556e-04  1.42954034e-04\n",
      "   1.10405926e-04 -1.02454109e-03  4.56610648e-04  7.30987108e-04\n",
      "  -7.99626637e-04  1.72559476e-04]\n",
      " [ 2.03178553e-04  7.84556945e-05 -1.46261086e-03  1.28031106e-04\n",
      "   2.53075078e-04 -6.00154259e-04  1.43302662e-03 -9.04597082e-04\n",
      "   1.23875181e-04 -1.71523479e-03  5.48071847e-04  9.17339216e-04\n",
      "   1.78408955e-04 -7.64176550e-04  1.18393473e-03 -3.32952472e-04\n",
      "   3.75835146e-04 -7.17344565e-06 -2.79360280e-04  1.71116245e-04\n",
      "   7.01198352e-04  1.06797716e-03 -3.67257441e-04  1.33227901e-04\n",
      "   1.43970503e-04  3.18815959e-04]\n",
      " [ 6.44624654e-04 -4.80423579e-04  1.31544812e-03  1.48470695e-04\n",
      "  -7.23726160e-04 -9.18578213e-04 -3.24304087e-04 -5.06468598e-04\n",
      "   4.76800609e-04  8.88055380e-04  2.20142723e-04  2.85604122e-04\n",
      "   2.43844745e-04  5.85147395e-04  8.37182969e-04 -3.84894750e-04\n",
      "   3.40890426e-04  1.22347386e-05 -2.79065388e-04  5.46231592e-04\n",
      "  -1.48171626e-03  1.55560368e-04 -7.87786512e-05  2.81816324e-04\n",
      "   4.00776566e-04 -4.47070073e-04]\n",
      " [ 9.56394406e-04  2.28823011e-04  2.69451186e-04  4.78414020e-05\n",
      "   1.97331562e-04  2.99939651e-04 -9.48219471e-04 -3.14688973e-05\n",
      "  -4.66083352e-04  6.24085673e-04  1.83516373e-03 -2.57803541e-04\n",
      "   5.46312871e-04  1.08237069e-04  7.01154367e-05  4.87561287e-04\n",
      "   3.75657053e-04  2.63352941e-07 -7.16261821e-04  9.22901545e-04\n",
      "  -3.68677713e-05 -5.25832600e-04  9.63782772e-04 -1.97791750e-04\n",
      "  -9.43036071e-04 -2.95010252e-04]\n",
      " [ 4.27278481e-04  1.32637896e-04  9.87629802e-04  1.25143523e-05\n",
      "   1.94665917e-04  2.89666881e-04  5.09232531e-05  8.40599870e-04\n",
      "   4.89188877e-04  1.11522446e-04  3.96043186e-04  4.18466863e-04\n",
      "  -5.90451649e-04 -6.48077209e-04 -4.41693371e-04  1.24239084e-03\n",
      "  -1.30492486e-03 -2.00990182e-05  7.47333692e-04  4.44539362e-04\n",
      "   4.43080529e-04  4.10156399e-04 -1.02240907e-03 -4.42329285e-04\n",
      "  -1.98181996e-04 -1.53790880e-03]\n",
      " [ 8.79231045e-04  9.17873779e-05 -5.16619727e-04  3.62651047e-04\n",
      "   5.27150124e-05  1.12253306e-03  6.84317156e-04  2.26867669e-05\n",
      "  -6.09539595e-04  3.01129452e-04 -5.39533215e-04  1.72466720e-04\n",
      "  -3.90723309e-04  6.90256570e-04 -2.26970375e-04 -1.14520023e-03\n",
      "  -7.94817699e-04  4.91285854e-06  4.08638255e-05  8.74001882e-04\n",
      "   9.69229898e-05  4.66824365e-04 -2.86574584e-04  7.29033816e-04\n",
      "  -3.49558983e-04 -2.28169924e-04]\n",
      " [ 1.03344835e-04 -4.03728216e-04  1.32561876e-03  8.95507854e-05\n",
      "  -5.62882030e-04  1.40312600e-04 -1.07406305e-03 -1.21440652e-03\n",
      "  -5.68531513e-04 -9.14842629e-04  1.55800684e-04 -1.62044833e-04\n",
      "   4.99521545e-04 -5.73564095e-04 -8.32763269e-04  2.62287031e-04\n",
      "   5.61087681e-04 -1.04926947e-06  1.19688403e-03  1.07582591e-04\n",
      "   1.45107695e-04 -1.93014625e-04  1.92029285e-03  2.24532626e-04\n",
      "   4.49349154e-04  8.49165935e-04]\n",
      " [ 8.56446191e-04  7.83581215e-04 -2.06959274e-04  4.90388871e-05\n",
      "  -2.82070013e-05  1.98557288e-03 -7.96388530e-04 -1.33924402e-03\n",
      "  -1.14065959e-03  1.64929954e-04 -1.31001561e-05  1.01412896e-03\n",
      "   9.23440728e-04  1.04381817e-03 -5.76999568e-04 -4.22936638e-04\n",
      "   5.48333293e-04  5.55411674e-06 -1.02739853e-03  9.97840456e-04\n",
      "   1.17546445e-03  6.03832549e-04 -1.78128126e-03  3.36620663e-04\n",
      "   7.47906717e-04  1.00264640e-04]\n",
      " [ 3.30229598e-04  1.64043781e-04 -6.18062463e-04  2.07857724e-05\n",
      "   2.60610395e-04 -1.73768351e-04  3.15059151e-05  1.03347040e-03\n",
      "  -1.60288009e-04  2.07882964e-03 -1.54008431e-03  6.27591900e-05\n",
      "   4.90904272e-04  1.14356553e-03  1.15345131e-03  6.34198267e-06\n",
      "  -1.62235399e-04 -6.47281982e-06 -3.78954419e-04  3.09356243e-04\n",
      "  -9.96207224e-05 -2.75857868e-04  6.35398340e-04 -3.49893759e-04\n",
      "   7.61927180e-04  4.20506792e-04]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function calls your function feedforward(..) \n",
    "and backpropagation(..) to train the neural network.\n",
    "\"\"\"\n",
    "def neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25):\n",
    "    Y = vectorize_outputs(y)\n",
    "    a1 = add_row_ones(X.T)\n",
    "    \n",
    "    # Random initialization of the parameters\n",
    "    Theta1 = np.random.randn(hunits, a1.shape[0])\n",
    "    Theta2 = np.random.randn(Y.shape[0], hunits+1)\n",
    "    \n",
    "    for itr in range(max_iterations):\n",
    "        # Feedforward and backpropagation to obtain the gradients\n",
    "        z2, a2, z3, a3 = feedforward(a1, Theta1, Theta2)\n",
    "        D1, D2 = backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2)\n",
    "        \n",
    "        # Using gradient descent to update the parameters\n",
    "        Theta1 = Theta1 - alpha * D1\n",
    "        Theta2 = Theta2 - alpha * D2\n",
    "        \n",
    "        if itr % 50 == 0:\n",
    "            print(\"itr = {}, cost = {}\".format(itr, E_unregularized(X, Y, Theta1, Theta2)), end=\" \\r\")\n",
    "    return Theta1, Theta2, D1, D2\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We call the above function to train the neural network (learn the parameters), \n",
    "then we predict the labels for the training set X and compute the accuracy on \n",
    "the training set. You should expect a training accuracy of more than 95%.\n",
    "\"\"\"\n",
    "Theta1, Theta2, D1, D2 = neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25)\n",
    "y_pred = predict(X, Theta1, Theta2)\n",
    "print()\n",
    "print(\"Accuracy: \", (y == y_pred).mean() * 100)\n",
    "# print(D1, D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "print(D1.shape, D2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "print(Theta1.shape, Theta2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "(25,)"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1z = D1[:,0]\n",
    "D1z.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "(25, 400)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1_rest = Theta1[:,1:]\n",
    "Theta1_rest.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Regularized Neural Networks\n",
    "After you have successfully run the previous algorithm, you will now add regularization to the gradient. To account for regularization, it turns out that you can add this as an additional term *after* computing the gradients using backpropagation.\n",
    "\n",
    "Specifically, after you have computed $\\Delta^{(l)}_{ij}$ using backpropagation, you should add regularization using\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\Theta^{(l)}_{ij}} E(\\Theta) = \\Delta^{(l)}_{ij} \\quad \\quad \\quad \\quad \\quad \\text{ for } j = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\Theta^{(l)}_{ij}} E(\\Theta) = \\Delta^{(l)}_{ij} + \\frac{\\lambda}{n} \\Theta^{(l)}_{ij} \\quad \\quad \\text{ for } j \\geq 1\n",
    "$$\n",
    "Note that we do not regularize the first column (i.e. where $j=0$) which is used for the bias term.\n",
    "\n",
    "Your task is to modify the function `neural_network_training(..)` in the Python code below to account for regularization. Note that the function now has an additional argument `lmd` which corresponds to the regularization hyperparameter $\\lambda$.\n",
    "\n",
    "With $\\lambda = 20$, you should be getting a training accuracy which is smaller than previously (the unregularized case, or when $\\lambda=0$). However, this DOES NOT necessarily mean that your neural network is now worse. Why? You are asked to answer this question *inside* the last comment in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function calls your functions feedforward(..) \n",
    "and backpropagation(..) to train the neural network.\n",
    "\"\"\"\n",
    "def neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25, lmd=20):\n",
    "    Y = vectorize_outputs(y)\n",
    "    a1 = add_row_ones(X.T)\n",
    "    \n",
    "    # Random initialization of the parameters\n",
    "    Theta1 = np.random.randn(hunits, a1.shape[0])\n",
    "    Theta2 = np.random.randn(Y.shape[0], hunits+1)\n",
    "    \n",
    "    for itr in range(max_iterations):\n",
    "        # Feedforward and backpropagation to obtain the gradients\n",
    "        z2, a2, z3, a3 = feedforward(a1, Theta1, Theta2)\n",
    "        D1, D2 = backpropagation(a1, z2, a2, z3, a3, Y, Theta1, Theta2)\n",
    "        \n",
    "        \"\"\" TODO:\n",
    "        Modify D1 and D2 here to account for regularization.\n",
    "        \"\"\"\n",
    "\n",
    "        # d1 take first column and save for later\n",
    "        D1z = D1[:,0]\n",
    "        D2z = D2[:,0]\n",
    "        Theta1_rest = Theta1[:,1:]\n",
    "        Theta2_rest = Theta2[:,1:]\n",
    "        D1 +=\n",
    "        D2 +=\n",
    "        # Using gradient descent to update the parameters\n",
    "        Theta1 = Theta1 - alpha * D1\n",
    "        Theta2 = Theta2 - alpha * D2\n",
    "        \n",
    "        if itr % 50 == 0:\n",
    "            print(\"itr = {}, cost = {}\".format(itr, E_regularized(X, Y, Theta1, Theta2, lmd)), end=\"\\r\")\n",
    "            \n",
    "    return Theta1, Theta2\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We call the above function to train the neural network (learn the parameters), \n",
    "then we predict the labels for the training set X and compute the accuracy on \n",
    "the training set. You should expect a training accuracy of less than 95%.\n",
    "\"\"\"\n",
    "Theta1, Theta2 = neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25, lmd=20)\n",
    "y_pred = predict(X, Theta1, Theta2)\n",
    "print(\"Accuracy: \", (y == y_pred).mean() * 100)\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Write inside this comment HERE (not outside) your answer to the following question:\n",
    "\n",
    "Question: Why your regularized neural network is considered to be better than the \n",
    "unregularized one (i.e. lambda = 0), even though the training accuracy that you \n",
    "achieve with the unregularized one is higher?\n",
    "\n",
    "WRITE YOUR (SHORT) ANSWER HERE:\n",
    "... ... ... ...\n",
    "... ... ... ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Visualizing the hidden layer\n",
    "One way to understand what your neural network is learning is to visualize what are the representations captured by the hidden units (units of the hidden layer). Informally, given a particular hidden unit, one way to visualize what it computes is to find an\n",
    "input $x$ that will cause it to activate (that is, to have a sigmoid activation value $a^{(l)}_{i}$ close to 1). For the neural network you trained, notice that the $i^{th}$ row of $\\Theta^{(1)}$ is a vector of dimension 401 that represents the parameter for the $i^{th}$ hidden unit. If we discard the bias term, we get a 400 dimensional vector that represents the weights from each input pixel to the hidden unit.\n",
    "\n",
    "Thus, one way to visualize the \"*representation*\" captured by the hidden unit is to reshape this 400 dimensional vector into a $20 \\times 20$ image and display it. The following Python code does this and show you an image (similar to the following figure) with 25 units, each corresponding to one hidden unit in the network.\n",
    "\n",
    "In your trained network, you should find that the hidden units correspond roughly to detectors that look for strokes and other patterns in the input.\n",
    "\n",
    "<img src=\"imgs/vizUnitsNN.png\" width=\"400px\" title=\"Visualization of Hidden Units\" alt=\"Visualization of Hidden Units\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hidden_units(Theta1, Theta2):\n",
    "    # Reshape Theta1 into 25 images of shape 20*20\n",
    "    images = Theta1[:, 1:].reshape((25, 20, 20))\n",
    "\n",
    "    # Plot with a grid of 5*5 = 25 images\n",
    "    fig, axes = plt.subplots(5, 5)\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            img = images[i*5+j].T\n",
    "            axes[i][j].imshow( img, cmap='gray' )\n",
    "            axes[i][j].axis(\"off\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Training the neural network with max_iterations=2000, alpha=0.5, hunits=25, lmd=20\n",
    "Theta1, Theta2 = neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25, lmd=20)\n",
    "\n",
    "# We call our above function to visualize the 25 hidden units as 20*20 images.\n",
    "visualize_hidden_units(Theta1, Theta2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3.1 Trying various values of $\\lambda$ and `max_iterations`\n",
    "\n",
    "In this section, you will get to try out different learning settings for the neural network to see how the performance of the neural network varies with the regularization parameter $\\lambda$ and the number of training steps (the `max_iterations` argument in the function `neural_network_training(..)`).\n",
    "\n",
    "Neural networks are very powerful models that can form highly complex decision boundaries. Without regularization, it is possible for a neural network to \"overfit\" a training set so that it obtains close to 100% accuracy on the training set but does not as well on new examples that it has not seen before. You can set the regularization $\\lambda$ to a smaller value and the `max_iterations` argument to a higher number of iterations to see this for youself.\n",
    "\n",
    "You will also be able to see for yourself the changes in the visualizations of the hidden units when you change the learning parameters $\\lambda$ and `max_iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train the ANN using some values of max_iterations and lmd.\n",
    "Theta1, Theta2 = neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25, lmd=5)\n",
    "# TODO: visualize the hidden units based on the parameters you got.\n",
    "visualize_hidden_units(Theta1, Theta2)\n",
    "\n",
    "# TODO: train the ANN using some other values of max_iterations and lmd.\n",
    "Theta1, Theta2 = neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25, lmd=20)\n",
    "# TODO: visualize the hidden units based on the parameters you got.\n",
    "visualize_hidden_units(Theta1, Theta2)\n",
    "\n",
    "# TODO: train the ANN using some other values of max_iterations and lmd.\n",
    "Theta1, Theta2 = neural_network_training(X, y, max_iterations=2000, alpha=0.5, hunits=25, lmd=20)\n",
    "# TODO: visualize the hidden units based on the parameters you got.\n",
    "visualize_hidden_units(Theta1, Theta2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}